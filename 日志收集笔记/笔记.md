## 一、需求

实时收集服务器日志同一存储到中心系统，并对日志建立索引，通过搜索即可快速定位找到对应日志，通过提供web界面实现日志检索与展示。

要求：日志量大，实现准实时收集，延迟控制在分钟级别，能够支持水平扩展。

### 业界方案

#### ELK

AppServer => LogstashAgent => ElasticSearchCluster => KibanaServer => Browser

##### 存在的问题

- 运维成本高，没增加一个日志收集项，都需要手动修改配置。
- ~~监控缺失、无法准确获取logstash的状态。~~
- 无法定制化开发与维护。

## 二、系统架构

![](.\Images\日志收集项目系统架构.png)

组件：

- Log Agent（生产者）：日志收集客户端，用于收集服务器上的日志。

- Kafka：高吞吐量的分布式队列。
- ElasticSearch：开源搜索引擎，提供HTTP RESTful的web接口。
- Kibana：开源的ES数据分析和可视化工具。

- tranfer（消费者）。

- etcd：配置管理，热加载（web界面实现）。

- Hadoop：分布式计算框架，大数据分布式处理平台。
- Storm：分布式实时计算系统。

### 技术栈

- 服务端agent开发。
- 后端服务组件开发。
- Kafka和zookeeper的使用。
- ElasticSearch和Kibana的使用。
- etcd的使用。

## 三、Kafka

前提：NSQ。

### 3.1 消息队列通信模型

#### 点对点模式

一对一，一条消息只能被消费一次，不存在重复消费。

#### 发布/订阅（topic）

一对多，消息生产者将消息发布到topic中，同时有多个消费者订阅（消费）该消息；与点对点相比，发布到topic的消息会被所有订阅者消费。

### 3.2 Kafaka简介

分布式数据流平台，可单机部署也可集群部署，提供发布/订阅功能，使用者可发送数据到Kafka中，也可从Kafka中读取数据；Kafka具有高吞吐、低延迟、高容错的特点。

### 3.3 Kafaka架构

Procuder => Kafaka Cluster（Broker-0、Broker-1...） => Consumer（Concumer Group A...）

- Procuder：生产者，消息入口。

- Kafka cluster：kafka集群，一台或多台服务器。
  - Broker：部署了Kafka实例的服务器节点，集群内编号唯一。
  - Topic：消息主题（分类），每个Broker可创建多个topic。
  - Partition：Topic的分区，用于负载，提高吞吐量，分区数据不重复。
  - Replication：分区副本，主分区故障时使用；副本默认数量10，数量不能大于Broker数量。
- Consumer：消费者，消息出口。
  -  Consumer Group：由多个消费者组成；同一个分区的数据只能被消费者组中的某一个消费者消费，同一个消费者组中的消费者可以消费同一个topic下不同分区的数据。

#### 工作流程

![](.\Images\Kafka工作流程.png)

说明：

1. 生产者从Kafka集群获取分区leader信息。
2. 生产者将消息发送到leader。
3. leader将消息写入本地磁盘。
4. follower从leader拉取消息数据。
5. follower将消息写入本地磁盘后向leader发送ACK。
6. leader收到所有follower的ACK后向生产者发送ACK。

#### 选择partition的原则

原则如下：

1. 写入时可以指定`partition`。
2. 未指定`partition`时，如果设置了`key`，则`hash`计算对应`partition`。
3. 未指定`partition`且未设置`key`时，使用轮询方式（按时间段）。

#### ACK应答机制

`procuder`在向Kafka写入消息时，可以设置参数来确认是否Kafka已接收到数据，参数取值为`0`、`1`、`all`。

- `0`：无需确认，安全性低、效率高。
- `1`：只确认`leader`已接收。
- `all`：确认`leader`已接收且`follower`已完成备份。

注：若向不存在的topic写数据，kafka将自动创建topic，partition和replication数量默认都为1.

#### Topic和数据日志

`topic`是同一类别的消息记录集合，一个主题通常有多个订阅者；对于每个`topic`，Kafka维护一个分区数据日志文件。每个`partition`都是一个有序并且不可变的消息记录集合，新消息写入时追加到`partition`末尾；在每个`partition`中，每条消息都被有序分配一个唯一标识`offset`，即偏移量。Kakfa只保证同一分区内的消息是有序的。Kafka可配置保留期限，过期时数据被清空。

#### Partition结构

Partition在服务器上的表现形式为文件夹，每个`partition`文件夹下有多组`segment`文件，每组`segment`文件包含`.index`文件、`.log`文件、`.timeindex`文件，其中`.log`文件用于存储消息，`.index`和`.timeindex`文件为索引文件，用于检索消息。

#### 消费数据

总结：

- 同一个分区的数据只能被消费者组中的某一个消费者实例消费。
- 一个消费者实例可以消费不同分区中的数据。

### 3.4 使用场景

#### 消息队列

跨进程通信、上下游消息传递、解耦。

#### 追踪网站活动

对网站活动进行追踪，将不同活动放入不同主题，供后续实时计算、实时监控等程序使用，也可导入数据仓库进行后续离线处理和生成报表。

#### Metrics

传输监控数据：聚合分布式应用程序的统计数据，将数据集中后进行同一的分析和展示。

##### 日志聚合

### 3.6 安装

#### 安装JDK

略。

#### 安装zookeeper

服务注册发现：调用方调用前先到注册中心查询可调用的服务。

下载地址：http://www.apache.org/dyn/closer.cgi/zookeeper/

#### 安装kafka

下载地址：http://kafka.apache.org/downloads（3.0.0版本有坑，使用2.8.1）

修改配置：./config/server.properties

```properties
# broker ID
broker.id=0
# 存储目录
log.dirs=D:/ProgramData/kafka-logs
# 分区数量
num.partitions=1
# zookeeper
zookeeper.connect=localhost:2181
```

修改配置：./config/zookeeper.properties

```properties
dataDir=D:/ProgramData/zookeeper-data
```

启动zookeeper（kafka自带）：

```powershell
.\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties
```

启动kafka：

```powershell
.\bin\windows\kafka-server-start.bat .\config\server.properties
```

启动kafka客户端：

```bash
.\bin\windows\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic web_log --from-beginning
```

## 四、Etcd

### 4.1 etcd简介

Go语言开发的高可用的分布式K-V存储系统，可用于配置共享和服务的注册和发现。类似于`zookeeper`和`consul`。特点如下：

- 完全复制：集群的每个节点都可使用完整的存档。
- 高可用性：避免硬件单点故障或网络问题。
- 一致性：每次读写都返回跨多主机的最新写入。
- 简单：定义良好、面向用户的API（gRPC）。
- 安全：实现了带有可选功能的客户端身份验证的自动化TLS。
- 快速：每秒10000次写入的基准速度。
- 可靠：使用**Raft算法**实现强一致、高可用的服务存储目录。

### 4.2 etcd应用场景

#### 服务发现

查找集群中可用的服务。

#### 配置中心

应用在启动时主动从etcd获取配置信息，同时在etcd节点上注册一个Watcher并等待，以后每次配置更新时，etcd都会通知订阅者，以达到获取最新配置信息的目录。

#### 分布式锁

Etcd使用Raft算法实现了强一致性，故全局数据一致，易于实现分布式锁。锁服务的两种使用方式，一是保持独占，二是控制时序。

- 保持独占：所有获取锁的用户中只有一个可得到，etcd实现了原子操作的API。
- 控制时序：所有需要获取锁的用户都将被安排执行，但锁的顺序全局唯一（确定执行顺序）。

### 4.3 zookeeper的缺点

缺点：

- 部署维护复杂。
- Java编写~~（垃圾）~~，依赖过多。
- 发展缓慢。

### 4.4 etcd安装

官网：https://etcd.io/

下载地址：https://github.com/etcd-io/etcd/releases/download/v3.3.13/etcd-v3.3.13-windows-amd64.zip

### 4.5 etcd使用

#### 启动服务端

```
.\etcd.exe
```

#### 设置API版本

```
set ETCDCTL_API=3
```

#### 客户端：设置K-V

```
.\etcdctl.exe --endpoints=http://127.0.0.1:2379 put name "okarin"
```

#### 客户端：获取K-V

```
.\etcdctl.exe --endpoints=http://127.0.0.1:2379 get name
```

### 4.6 etcd集群搭建

https://www.cnblogs.com/51wansheng/p/10234036.html

### 4.7 go语言操作etcd

安装：

```powershell
go get go.etcd.io/etcd/clientv3
# go mod edit -replace github.com/coreos/bbolt@v1.3.4=go.etcd.io/bbolt@v1.3.4
```

可能出现的问题：http://wearygods.online/articles/2020/09/17/1600327573429.html

```
replace github.com/coreos/bbolt v1.3.4 => go.etcd.io/bbolt v1.3.4
replace google.golang.org/grpc => google.golang.org/grpc v1.26.0
```

示例：

```go
package main

import (
	"context"
	"fmt"
	"time"

	"go.etcd.io/etcd/clientv3"
)

func main() {
	client, err := clientv3.New(clientv3.Config{
		Endpoints:   []string{"127.0.0.1:2379"},
		DialTimeout: time.Second * 5,
	})
	if err != nil {
		fmt.Printf("connect to etcd failed, err:%v\n", err)
		return
	}
	defer client.Close()

	// put
	ctx, cancel := context.WithTimeout(context.Background(), time.Second*1)
	_, err = client.Put(ctx, "group", "LAB")
	if err != nil {
		fmt.Printf("put to etcd failed, err:%v\n", err)
		return
	}
	cancel()

	// get
	ctx, cancel = context.WithTimeout(context.Background(), time.Second*1)
	rsp, err := client.Get(ctx, "group")
	if err != nil {
		fmt.Printf("get from etcd failed, err:%v\n", err)
		return
	}

	for _, kv := range rsp.Kvs {
		fmt.Printf("key:%s value:%s\n", kv.Key, kv.Value)
	}
	cancel()
}
```

### 4.8 watch

监控。

```go
package main

import (
	"context"
	"fmt"
	"time"

	"go.etcd.io/etcd/clientv3"
)

func main() {
	client, err := clientv3.New(clientv3.Config{
		Endpoints:   []string{"127.0.0.1:2379"},
		DialTimeout: time.Second * 5,
	})
	if err != nil {
		fmt.Printf("connect to etcd failed, err:%v\n", err)
		return
	}
	defer client.Close()

	// watch
	watchCh := client.Watch(context.Background(), "group")
	for rsp := range watchCh {
		for _, event := range rsp.Events {
			fmt.Printf("type:%s key:%s value:%s\n", event.Type, event.Kv.Key, event.Kv.Value)
		}
	}
}
```

## 五、准备工作

### 4.1 使用sarama向kafka发送消息

下载sarama：

```powershell
go get github.com/Shopify/sarama
```

示例：

```go
package main

import (
	"fmt"

	"github.com/Shopify/sarama"
)

func main() {

	// 1.生产者配置
	config := sarama.NewConfig()
	config.Producer.RequiredAcks = sarama.WaitForAll          // ACK
	config.Producer.Partitioner = sarama.NewRandomPartitioner // 分区
	config.Producer.Return.Successes = true                   // 交付成功消息

	// 2.连接kafka
	client, err := sarama.NewSyncProducer([]string{"127.0.0.1:9092"}, config)
	if err != nil {
		fmt.Println("producer closed, err:", err)
		return
	}
	defer func(client sarama.SyncProducer) {
		err := client.Close()
		if err != nil {
			fmt.Println("client close failed, err:", err)
		}
	}(client)

	// 3.封装消息
	msg := &sarama.ProducerMessage{
		Topic: "test",
		Value: sarama.StringEncoder("FIRST TEST"),
	}

	// 4.发送消息
	pid, offset, err := client.SendMessage(msg)
	if err != nil {
		fmt.Println("send msg failed, err:", err)
		return
	}
	fmt.Printf("pid:%v offset:%v\n", pid, offset)
}
```

消费消息：

```powershell
.\bin\windows\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic test --from-beginning
```

### 4.2 使用tailf包读取日志文件

示例：

```go
package main

import (
	"fmt"
	"github.com/hpcloud/tail"
)

func main(){
	filename := `./xx.log`
	config := tail.Config{
		Location:  &tail.SeekInfo{
			Offset: 0,
			Whence: 2,
		},
		ReOpen:    true,
		MustExist: false,
		Poll:      true,
		Follow:    true,
	}

	//打开文件读取数据
	file, err := tail.TailFile(filename, config)
	if err != nil {
		fmt.Printf("tail %s failed, err:%v\n\n", filename, err)
		return
	}

	var(
		msg *tail.Line
		ok bool
	)

	for {
		msg, ok = <- file.Lines
		if !ok {
			fmt.Printf("tail file close reopen, filename:%s\n", file.Filename)
			break
		}
		fmt.Printf("msg:%s", msg.Text)
	}
}
```

### 4.3 使用sarama从kafka读取消息





## 六、日志收集agent开发

### 配置文件版

梳理：

- 使用`ini`包读取配置。
- 使用`tailf`包读取日志并存入`chan`。
- 使用`sarema`包操作kafka，从`chan`读取日志并发往`kafka`。
- 使用`logrus`打印日志。
- 使用方法封装对外部包提供的变量。

### etcd版

配置多个topic：

```json
[
    {
        "path": "D:/ProgramData/LogAgent/logs/s4.log",
        "topic": "s4_log"
    },
    {
        "path": "D:/ProgramData/LogAgent/logs/web.log",
        "topic": "web_log"
    }
]
```

压缩后：

```json
[{"path":"D:/ProgramData/LogAgent/logs/s4.log","topic":"s4_log"},{"path":"D:/ProgramData/LogAgent/logs/web.log","topic":"web_log"}]
```

思路：

- config模块在etcd配置项增加日志Key字段。
- main函数根据Key从etcd模块读取对应的配置信息。
- tailfile模块根据配置信息启动任务。
- 监控etcd中Key（配置）变化。
- 根据最新配置判断是否新增、删除或保持任务。
- 集成IP：etcd的key中加入IP信息，加载配置时读取本机IP生成Key然后向etcd中查找。

## 七、系统监控

### 7.1 获取系统信息

#### 获取主机IP

集成到LogAgent（多个网卡如何解决）。

```go
func GetLocalIP() (ip string, err error) {
	address, err := net.InterfaceAddrs()
	if err != nil {
		return
	}

	for _, addr := range address {
		ipAddr, ok := addr.(*net.IPNet)
		if !ok {
			continue
		}
		if ipAddr.IP.IsLoopback() {
			continue
		}
		if !ipAddr.IP.IsGlobalUnicast() {
			continue
		}
		ip = ipAddr.IP.String()
		return
	}
	return
}

func GetLocalIPByDial() (ip string, err error) {
	conn, err := net.Dial("udp", "8.8.8.8:80")
	if err != nil {
		return
	}
	defer conn.Close()

	addr := conn.LocalAddr().(*net.UDPAddr)
	ip = strings.Split(addr.IP.String(), ":")[0]
	return
}
```

#### 获取CPU等信息

使用`gopsutil`包。

获取CPU信息：

```go
// GetCpuLoad 获取CPU负载
func GetCpuLoad() {
	info, err := load.Avg()
	if err != nil {
		return
	}
	fmt.Println(info)
}

// GetMemInfo 获取内存信息
func GetMemInfo() {
	info, err := mem.VirtualMemory()
	if err != nil {
		return
	}
	fmt.Println(info)
}
```

获取内存信息：

```go
// GetMemInfo 获取内存信息
func GetMemInfo() {
	info, err := mem.VirtualMemory()
	if err != nil {
		return
	}
	fmt.Println(info)
}
```

获取host信息：

```go
// GetHostInfo host信息
func GetHostInfo() {
	host, err := host2.Info()
	if err != nil {
		return
	}
	fmt.Println(host)
}
```

获取磁盘信息：

```go
// GetDiskInfo 磁盘信息
func GetDiskInfo() {
	parts, err := disk.Partitions(true)
	if err != nil {
		return
	}
	fmt.Println(parts)
	for _, part := range parts {
		stat, err := disk.Usage(part.Mountpoint)
		if err != nil {
			return
		}
		fmt.Println(stat)
	}

	// 磁盘IO信息
	ioStats, _ := disk.IOCounters()
	for key, stat := range ioStats {
		fmt.Printf("DiskName:%v, IOStatus:%v\n", key, stat)
	}
}
```

获取网络信息：

```go
// GetNetInfo 网络信息
func GetNetInfo() {
	netIOs, err := net.IOCounters(true)
	if err != nil {
		return
	}

	for _, netIO := range netIOs {
		fmt.Println(netIO)
	}
}
```

### 7.2 influxDB使用

#### influx简介

使用`influxDB`存储监控信息：时序数据库，适用sql语法。

官网：https://portal.influxdata.com/downloads/

下载地址：https://dl.influxdata.com/influxdb/releases/influxdb-1.8.10_windows_amd64.zip

修改配置：`influx.db`

```conf
[meta]
  # Where the metadata/raft database is stored
  # dir = "/var/lib/influxdb/meta"
  dir = "D:/ProgramData/influxdb/meta"
  
[data]
  # The directory where the TSM storage engine stores TSM files.
  dir = "D:/ProgramData/influxdb/data"
  wal-dir = "D:/ProgramData/influxdb/wal"
```

运行：

```
./influxdb.exe
```

#### influx概念

总结：

- database：数据库。
- measurement：数据表。
- point：数据行，由时间戳、数据、标签组成。
  - time：每条记录的时间，主索引，自动创建。
  - field：记录值，如温度、湿度等。
  - tags：有索引的属性，地区、海拔、网卡。

- series：数据的集合。

#### 使用

安装：

```
go get -u github.com/influxdata/influxdb1-client/v2
go get github.com/influxdata/influxdb-client-go
```

创建数据库：

```
create database test;
```

示例（插入数据、查询数据）：

```go
package main

import (
	"fmt"
	client "github.com/influxdata/influxdb1-client/v2"
	"time"
)

// 连接
func connFlux() (cli client.Client, err error) {
	cli, err = client.NewHTTPClient(client.HTTPConfig{
		Addr:     "http://localhost:8086",
		//Username: "admin",
		//Password: "",
	})
	if err != nil {
		return
	}
	return
}

// 查询
func queryDB(cli client.Client, cmd string) (res []client.Result, err error) {
	qry := client.Query{
		Command:  cmd,
		Database: "test",
	}
	if rsp, err := cli.Query(qry); err == nil {
		if rsp.Error() != nil {
			return res, rsp.Error()
		}
		res = rsp.Results
	} else {
		return res, err
	}
	return res, nil
}

// 插入
func insertPoints(cli client.Client) {
	points, err := client.NewBatchPoints(client.BatchPointsConfig{
		Database: "test",
		Precision: "s", // 精度，默认ns
	})
	if err != nil {
		fmt.Printf("insert failed:, err:%v", err)
		return
	}
	tags := map[string]string{"cpu":"ih-cpu"}
	fields := map[string]interface{}{
		"idle": 201.1,
		"system": 43.3,
		"user": 86.6,
	}

	point, err := client.NewPoint("cpu_usage", tags, fields, time.Now())
	if err != nil {
		fmt.Printf("insert failed:, err:%v", err)
		return
	}
	points.AddPoint(point)
	err = cli.Write(points)
	if err != nil {
		fmt.Printf("insert failed:, err:%v", err)
		return
	}
	fmt.Println("insert success")
}

func main() {
	conn, err := connFlux()
	if err != nil {
		return
	}
	fmt.Println(conn)

	insertPoints(conn)

	qstr := fmt.Sprintf("SELECT * FROM %s LIMIT %d", "cpu_usage", 10)
	res, err := queryDB(conn, qstr)
	if err != nil {
		fmt.Printf("query failed:, err:%v", err)
		return
	}
	for _, row := range res[0].Series[0].Values {
		for j, value := range row {
			fmt.Printf("index: %d, value: %v\n", j, value)
		}
	}
}
```

### 7.3 grafana数据可视化

官网：https://grafana.com/

配置：拷贝`defaults.ini`重命名为`custom.ini`

```
[database]
type = sqlite3
...
```

启动：

```
./bin/grafana-server.exe
```

登录：密码admin

```
127.0.0.1：3000
```

- 选择数据库：influxDB

  - URL：http://localhost:8086

  - InfluxDB Details

  - Database：test（数据库名）

  - User & Password：空

  - HTTP Method：GET
  - Save & test

- 添加仪表盘：Dashboard

  - 添加Query：idle、system、user。







## 环境搭建

### docker

#### zookeeper

```bash
docker pull wurstmeister/kafka
docker run -d --name zookeeper -p 2181:2181 -t zookeeper
```

#### kafka

```bash
docker pull wurstmeister/kafka
docker run  -d --name kafka -p 9092:9092  --env KAFKA_ADVERTISED_HOST_NAME=localhost  -e KAFKA_ZOOKEEPER_CONNECT=192.168.99.100:2181 -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.99.100:9092  -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 -e KAFKA_HEAP_OPTS="-Xmx256M -Xms128M"  wurstmeister/kafka 
```

#### kafka验证

```bash
docker exec -it kafka bash
cd /opt/kafka_*
./kafka-topics.sh --create --zookeeper 192.168.31.200:2181 --replication-factor 1 --partitions 8 --topic test
./kafka-console-producer.sh --broker-list localhost:9092 --topic test
```

#### kafka监视平台

```bash
docker pull sheepkiller/kafka-manager
docker run -it -d --rm  -p 9000:9000 -e ZK_HOSTS="192.168.99.100:2181"  sheepkiller/kafka-manager
```



















